
<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link media="screen" rel="stylesheet" type="text/css" href="/assets/css/jonplummer.css">

    <meta name="robots" content="max-image-preview:large">

    <link rel="profile" href="http://gmpg.org/xfn/11">
    <link rel="me" href="https://mas.to/@jplummer">
    <link rel="me" href="https://bsky.app/profile/jonplummer.com">
    <link rel="canonical" href="https://jonplummer.com/2025/07/12/our-position-on-ai-tools/">
    <link rel="alternate" type="application/rss+xml" title="Jon Plummer: Today I Learned: Posts" href="/feed.xml">
    <link rel="alternate" type="application/rss+xml" title="Jon Plummer: Today I Learned: Links" href="/links-feed.xml">

    <title>Our position on AI tools</title>

    <link rel="icon" href="/assets/images/2021/02/jp_round-48x48.jpg" sizes="32x32">
    <link rel="icon" href="/assets/images/2021/02/jp_round.jpg" sizes="192x192">
    <link rel="apple-touch-icon" href="/assets/images/2021/02/jp_round-180x180.jpg">
    <meta name="msapplication-TileImage" content="/assets/images/2021/02/jp_round.jpg">

    <meta name="description" content="Jon Plummer is a UX design leader and mentor. Read his thoughts on design, leadership, and product development.">
    <meta name="generator" content="11ty">

    <meta property="og:locale" content="en_US">
    <meta property="og:site_name" content="Jon Plummer">
    <meta property="og:title" content="Our position on AI tools">
    <meta property="og:url" content="https://jonplummer.com/2025/07/12/our-position-on-ai-tools/">
    <meta property="og:type" content="website">
    <meta property="og:description" content="Jon Plummer is a UX design leader and mentor. Read his thoughts on design, leadership, and product development.">
    <meta property="og:image" content="https://jonplummer.com/assets/images/2021/05/og-image.png">
    <meta property="og:image:url" content="https://jonplummer.com/assets/images/2021/05/og-image.png">
    <meta property="og:image:secure_url" content="https://jonplummer.com/assets/images/2021/05/og-image.png">
    <meta name="twitter:title" content="Our position on AI tools">
    <meta name="twitter:url" content="https://jonplummer.com/2025/07/12/our-position-on-ai-tools/">
    <meta name="twitter:description" content="Jon Plummer is a UX design leader and mentor. Read his thoughts on design, leadership, and product development.">
    <meta name="twitter:image" content="https://jonplummer.com/assets/images/2021/05/og-image.png">
    <meta name="twitter:card" content="summary_large_image">

</head>

<body>
<header>
    <a class="skip" href="#main">Skip to content</a>
    <hgroup>
        <h1><a href="/" rel="home">Jon Plummer</a></h1>
        <p>Today I Learned</p>
    </hgroup>
    
<nav>
    <ul>
        <li><a href="/about/" >About me</a></li>
        <li><a href="/now/" >Now</a></li>
        <li><a href="/portfolio/" >Portfolio</a></li>
    </ul>
</nav>
</header>

<main id="main" aria-label="Main content">
    


<article>
    <header>
        <h1><a href="/2025/07/12/our-position-on-ai-tools/" rel="bookmark">Our position on AI tools</a></h1>
    </header>
    <section>
        <p>(This is a work in progress, but a pretty good start)</p>
<h2>Designing AI-powered product experiences</h2>
<h3>User needs and customer problem first</h3>
<p><strong>Solving a valuable customer problem is paramount</strong>. Before selecting any technological solution, including AI, we prioritize understanding user needs and clearly defining the problem we aim to solve. Any AI application must serve a genuine, identified user need, rather than being a solution in search of a problem.</p>
<h3>Transparency, explainability, and trust</h3>
<p>We recognize that users may be curious, or even apprehensive, about how AI-powered features operate. While full algorithmic explainability may not always be feasible or necessary, we commit to being <strong>transparent about the inputs and context</strong> that drive AI outputs. We hope to empower users with a <strong>sense of control</strong>, offering opportunities to <strong>validate choices, preview actions</strong>, and interact with AI as an assistant before letting it run as an autonomous agent. Maintaining an <strong>audit trail of AI actions</strong> also supports accountability and trust.</p>
<h3>Handling errors and edge cases</h3>
<p>We acknowledge that AI-powered features will sometimes produce wrong or unexpected outputs. Our design approach for these scenarios focuses on <strong>graceful error handling</strong> and keeping the <strong>human in the loop</strong>. This means</p>
<ul>
<li><strong>Anticipating and mitigating</strong> potential issues through careful AI setup and training</li>
<li>Designing interfaces that offer <strong>previews, recommendations, and clear actions</strong> rather than proceeding blindly</li>
<li>Ensuring mechanisms for users to easily <strong>correct, override, or provide feedback</strong> on AI outputs</li>
<li>Maintaining a design philosophy where the <strong>AI recommends and assists</strong>, allowing users to retain ultimate control until they explicitly release the system to act.</li>
</ul>
<h3>Ethical design and bias mitigation</h3>
<p>We strive to <strong>reduce bias</strong> in AI-powered features by</p>
<ul>
<li>Grounding our understanding in <strong>real customer knowledge</strong> rather than internal assumptions.</li>
<li>Working with and analyzing <strong>customer data responsibly</strong>, without alteration, and ensuring its privacy and security</li>
<li>Establishing processes for <strong>monitoring the output of our features</strong> for unintended biases that may emerge</li>
</ul>
<h3>Iteration and learning through metrics</h3>
<ul>
<li><strong>Clear project goals</strong> define success.</li>
<li><strong>Success metrics</strong> (e.g., accuracy, recall, task completion rates) and <strong>experiential metrics</strong> (e.g., user satisfaction, perceived control, trust) are established upfront.</li>
<li>Continuous <strong>monitoring and analysis of these metrics</strong> drive iterative improvement, allowing us to refine the AI's performance and the user experience over time.</li>
</ul>
<h2>Using AI tools in day-to-day UX work</h2>
<p>Our UX team embraces the strategic and responsible integration of AI tools into our daily workflows to enhance our capabilities and deliver more valuable experiences.</p>
<h3>Strategic tool adoption and augmentation</h3>
<p>We are actively <strong>experimenting with AI tools</strong> like Figma Make, ChatGPT, and Gemini to understand their potential. Our focus is not merely on speed, but on how these tools can <strong>enhance our ability to deliver valuable and usable experiences</strong>. We view AI primarily as an augmentation to our existing skills, particularly for</p>
<ul>
<li><strong>Inspiration and ideation</strong>: Generating diverse concepts, content variations, or design alternatives.</li>
<li><strong>Early-stage prototyping</strong>: Quickly sketching out ideas.</li>
<li><strong>Analyzing research data</strong>: Identifying patterns or themes in qualitative data (with careful oversight).</li>
</ul>
<h3>Maintaining UX quality through human oversight</h3>
<p>The ultimate <strong>responsibility for UX quality remains with the human designer</strong> and the members of the team with which they work. When using AI tools, each designer is accountable for the quality and accuracy of the output on their projects, regardless of AI assistance. We commit to <strong>human oversight and critical evaluation</strong> of any AI-generated content or insights. AI is a tool to assist, not replace, the designer's judgment, expertise, and empathy. All AI-assisted work undergoes the same <strong>review and validation processes</strong> as any UX work.</p>
<h3>Continuous learning and cross-pollination</h3>
<p>We encourage designers to</p>
<ul>
<li>Actively <strong>experiment with new AI tools and techniques</strong></li>
<li><strong>Share their learnings and best practices</strong> with the wider UX team and their project teams</li>
<li>Replicate and build upon the successful experiments of others</li>
<li>Embrace a <strong>fluidity in job boundaries</strong>, recognizing that AI tools may enable designers to contribute to areas traditionally outside core UX, fostering greater cross-functional collaboration</li>
</ul>
<h3>Ethical use of AI tools and intellectual property</h3>
<p>Our ethical considerations for designing AI-powered products extend to our use of AI tools. We commit to</p>
<ul>
<li><strong>Transparency</strong>: Clearly acknowledging when AI tools have been used in our work, internally and externally where relevant. We will never misrepresent AI-assisted work as purely human-created</li>
<li><strong>Data privacy and IP</strong>: Exercising caution regarding proprietary or sensitive customer data when interacting with external AI models. We will ensure we adhere to company policies and legal guidelines regarding data input into AI tools and the intellectual property of generated outputs</li>
<li><strong>Maintaining control</strong>: Never ceding our understanding or control of customer knowledge, the design process, or design work to AI tools. The human designer remains the expert and ultimate decision-maker, responsible for the integrity of their work and the insights and design artifacts they share</li>
</ul>

    </section>
    <footer>
        <p class="posted-on"><time datetime="2025-07-12T12:00:00-08:00">Jul 12, 2025</time></p>
    </footer>
</article>

<nav class="post-navigation">
    
    
    
    <a href="/2024/11/02/what-went-right-in-october/" class="prev">← Previous post: What went right in October?</a>
    

    
    <a href="/2025/07/12/what-went-right-since-october-2024/" class="next">Next post: What went right since October 2024? →</a>
    
</nav>
</main>

<footer aria-label="Site footer">
    
<p class="license">Copyright 2025 Jon Plummer</p>
</footer>
</body>
</html>